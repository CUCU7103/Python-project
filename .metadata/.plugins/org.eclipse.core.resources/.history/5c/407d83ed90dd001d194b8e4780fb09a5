# 멀티 프로세싱 연습 : 웹 스크래핑
import requests
from bs4 import BeautifulSoup as bs  # BeautifulSoup 마크업 언어, html,xml에서만 사용한다.
import time

def get_links():
    urldata = requests.get('https://beomi.github.io/beomi.github.io_old/').text
    # print(urldata)
    soup = bs(urldata,'html.parser') # BeautifulSoup의 객체가 됨
    #print(soup)
    my_titles = soup.select('h3 > a') # h3의 직계자손 a를 가져온다.
    # print(my_titles) # list type으로 정보를 가져온다. 
    
    datas = []

    for title in my_titles:
        datas.append(title.get('href')) # url에서 https://beomi.github.io가 빠져있다.
    # print(data)
    return datas

def get_datas(link):
    abs_link = 'https://beomi.github.io' + link # url 완성시킨다.
    # print(abs_link) 
    contents = requests.get(abs_link).text
    soup = bs(contents, 'html.parser') # BeautifulSoup의 객체가 됨
    # soup에는 해당 사이트의 자료가 담겨 있다.
    #얘를 써먹을 건 x 처리시간에만 관심이 있기에 
    print(soup)
    print(soup.select('h1')[0].text)
    
    
if __name__ =='__main__':
    start_time = time.time() # 현재 시간을 의미함.
    
    for link in get_links():
        get_datas(link)
        
    print('지연시간 : %s초'%(time.time() - start_time))